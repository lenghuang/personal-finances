{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1948655",
   "metadata": {},
   "source": [
    "# Budget Analysis V1\n",
    "\n",
    "This is my second attempt at viewing my spending data. In `v0`, we explored how to deduplicate the data across `*.csv` files for when I arbitrarily download multiple files. First, I'm going to construct all the AI generated code into the block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a526ca48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== READING IN FILES ===\n",
      "\n",
      "✅ Read in frame transactions_2025_06_13.csv with shape (1988, 9)\n",
      "✅ Read in frame transactions_dummy_to_test_duplicates.csv with shape (1988, 9)\n",
      "\n",
      "=== CONVERTING TYPES ===\n",
      "\n",
      "✅ Converted date string to_datetime\n",
      "✅ Converted boolean strings to boolean\n",
      "✅ Converted boolean strings to boolean\n",
      "✅ Converted amount strings to numeric\n",
      "\n",
      "=== ADDING ROW HASHES ===\n",
      "\n",
      "✅ Created columns IntraKey, CrossKey, and RowID\n",
      "✅ Set RowID as index\n",
      "\n",
      "=== COALESCING DUPLICATES on key='CrossKey' ===\n",
      "\n",
      "  Merging 2 rows for group '0a85a'. RowIDs: ['0a85a_1', '0a85a_2']\n",
      "  Merging 2 rows for group '0dd4d'. RowIDs: ['0dd4d_1', '0dd4d_2']\n",
      "  Merging 3 rows for group '0f0d5'. RowIDs: ['0f0d5_1', '0f0d5_2', '0f0d5_3']\n",
      "  ... (remaining rows hidden)\n",
      "\n",
      "✅ Total rows after de-duplication: 3885\n",
      "\n",
      "=== REMOVING DUPLICATES on key='IntraKey' ===\n",
      "\n",
      "  Removing 1939 duplicate rows:\n",
      "  RowID: 47 | Date: 2025-02-10 00:00:00 | Desc: FID BKG SVC LLC DES MONEYLINE INDN LEN G HUANG CO PPD | Amt: -200.0\n",
      "  RowID: 82 | Date: 2024-04-27 00:00:00 | Desc: BROOME LLC | Amt: -16.05\n",
      "  RowID: 135 | Date: 2024-03-04 00:00:00 | Desc: NEW BORGO SRLS ROMA | Amt: -6.51\n",
      "  RowID: 137 | Date: 2024-12-17 00:00:00 | Desc: CHASE CREDIT CRD DES AUTOPAY INDN HUANG LEN G CO PPD | Amt: -50.68\n",
      "  RowID: 156 | Date: 2024-10-28 00:00:00 | Desc: LIC GOURMET ORGANIC DEL | Amt: -1.04\n",
      "  ... and 1936 more duplicates\n"
     ]
    }
   ],
   "source": [
    "import finance_cleaner as fc\n",
    "\n",
    "df = fc.clean_transactions(\"../data/transactions_*.csv\")\n",
    "df.to_csv('../data/finance_cleaner_output.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909a278f",
   "metadata": {},
   "source": [
    "# LLM Integration\n",
    "\n",
    "Let's do some set up so that we can use LLM's to parse and understand our CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "050b6a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Budget Analysis ===\n",
      "Here's a summary of the transaction data:\n",
      "\n",
      "*   The data contains financial transactions.\n",
      "*   Includes information like amount, account, category, and date.\n",
      "*   Shows descriptions of the transactions.\n",
      "*   Mentions the institution where the transaction occurred.\n",
      "*   Some transactions are transfers from Ally Bank to a person.\n",
      "*   Venmo transactions involve energy, rideshares, and income.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from openrouter import OpenRouterClient\n",
    "\n",
    "# Set up the client\n",
    "client = OpenRouterClient()\n",
    "\n",
    "# Get first 5 rows as string\n",
    "first_5_rows = df.head(5).to_string()\n",
    "\n",
    "# Query LLM with budget expert system prompt\n",
    "response = client.quick_query(\n",
    "    first_5_rows,\n",
    "    system_message=\"Provide a brief summary of this transaction data, with short sentences and bullet points\"\n",
    ")\n",
    "\n",
    "print(\"\\n=== Budget Analysis ===\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c07a2d",
   "metadata": {},
   "source": [
    "# More Nuanced Category Understanding\n",
    "\n",
    "With this in mind, we can seek to accomplish a more nuanced understanding of how we organize data. Rather than providing hardcoded regex rules, I seek to provide a list of human language rules that we can use to get more nuanced understandings of the data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
